{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/changhee/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "DATA_MODE  = 'BC_STAGE3' #{BS_STAGE3, SYNTHETIC}\n",
    "##############################################\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "import class_clustering as clustering\n",
    "from class_DeepTPC import DeepTPC\n",
    "import train\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_MODE == 'BC_STAGE3':\n",
    "    data_M, data_D, data_T, data_X, data_Y_180, event_list, feat_list, label_180_list = impt.import_PHE_Stage3_version4(max_length=None)\n",
    "\n",
    "    last_seq_idx = np.argmax(data_T, axis=1).reshape([-1])\n",
    "    data_Mask = np.zeros([np.shape(data_M)[0], np.shape(data_M)[1]])\n",
    "\n",
    "    for i in range(np.shape(data_Mask)[0]):\n",
    "        data_Mask[i, (last_seq_idx[i]-1)] = 1\n",
    "\n",
    "elif DATA_MODE == 'SYNTHETIC': \n",
    "    data_M, data_D, data_T = impt.import_synthetic_HawkesProcess()\n",
    "    data_X = np.zeros([np.shape(data_M)[0], 1]) ##if not static feature is used\n",
    "    \n",
    "    last_seq_idx = np.argmax(data_T, axis=1).reshape([-1])\n",
    "    data_Mask = np.zeros([np.shape(data_M)[0], np.shape(data_M)[1]])\n",
    "\n",
    "    for i in range(np.shape(data_Mask)[0]):\n",
    "        data_Mask[i, (last_seq_idx[i])] = 1\n",
    "    #     data_Mask[i, (last_seq_idx[i]-1)] = 1  #if EOS available\n",
    "\n",
    "num_Event       = np.shape(data_M)[2]\n",
    "max_length      = np.shape(data_M)[1]\n",
    "num_Feature     = np.shape(data_X)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_itr = 0 \n",
    "seed = 1234\n",
    "\n",
    "(tr_M,te_M, tr_D,te_D, tr_T,te_T, tr_X,te_X, tr_Mask,te_Mask) = train_test_split(\n",
    "    data_M, data_D, data_T, data_X, data_Mask, test_size=0.2, random_state=seed+out_itr\n",
    ")\n",
    "\n",
    "init_path = './sample/itr_' + str(out_itr) + '/'\n",
    "\n",
    "if not os.path.exists(init_path):\n",
    "    os.makedirs(init_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NETWORK PARAMETERS\n",
    "# RNN\n",
    "h_dim1          = 50 #RNN hidden nodes per layer\n",
    "num_layers_RNN  = 2\n",
    "RNN_type        = 'GRU'\n",
    "RNN_active_fn   = tf.nn.tanh\n",
    "\n",
    "# FCNet\n",
    "h_dim2          = 50 #FC hidden nodes\n",
    "\n",
    "\n",
    "# Clustering\n",
    "L               = 10 # points for trapazoid approx. on the distance in the output space\n",
    "delta_range     = np.linspace(0, np.percentile(tr_D[tr_D != 0], 95), L) \n",
    "# delta_range     = np.linspace(0, np.max(data_D), L)\n",
    "\n",
    "# Others\n",
    "initial_W       = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = {\n",
    "    'num_Event':num_Event,\n",
    "    'max_length':max_length,\n",
    "    'num_Feature':num_Feature\n",
    "}\n",
    "\n",
    "network_settings = {\n",
    "    'h_dim1':h_dim1,\n",
    "    'num_layers_RNN':num_layers_RNN,\n",
    "    'RNN_type':RNN_type,\n",
    "    'RNN_active_fn':RNN_active_fn,\n",
    "    \n",
    "    'h_dim2':h_dim2,\n",
    "    \n",
    "    'L':L,\n",
    "    'delta_range':delta_range,\n",
    "    'initial_W':initial_W\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = {\n",
    "    'M':tr_M,\n",
    "    'D':tr_D,\n",
    "    'T':tr_T,\n",
    "    'X':tr_X,\n",
    "    'Mask':tr_Mask,\n",
    "}\n",
    "\n",
    "train_parameters_init = {\n",
    "    'mb_size': 64,\n",
    "    'lr_train': 1e-3,\n",
    "    'k_prob': 0.7,\n",
    "    'seed':1234+out_itr,\n",
    "    'ITERATION':40000\n",
    "}\n",
    "\n",
    "num_Cluster = 4\n",
    "\n",
    "train_parameters_cluster = {\n",
    "    'num_Cluster': num_Cluster,\n",
    "    'alpha': 0.1,\n",
    "    'beta': 0.1,\n",
    "    'beta_cluster': 0.1,\n",
    "    'beta_ms': (num_Event - 1) * [1.0],\n",
    "    'gamma': 0.1,\n",
    "    'ITERATION': 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved...\n",
      "ITR 0100: || MLE_loss=3965.5044 | va_MLE_loss=81.4666\n",
      "ITR 0200: || MLE_loss=177.8243 | va_MLE_loss=84.7059\n",
      "ITR 0300: || MLE_loss=134.1672 | va_MLE_loss=85.1686\n",
      "ITR 0400: || MLE_loss=101.3748 | va_MLE_loss=84.3129\n",
      "ITR 0500: || MLE_loss=94.2499 | va_MLE_loss=83.7492\n",
      "ITR 0600: || MLE_loss=96.2044 | va_MLE_loss=83.6655\n",
      "ITR 0700: || MLE_loss=92.6347 | va_MLE_loss=83.2330\n",
      "ITR 0800: || MLE_loss=92.6354 | va_MLE_loss=82.8953\n",
      "ITR 0900: || MLE_loss=85.4080 | va_MLE_loss=82.2874\n",
      "ITR 1000: || MLE_loss=86.6301 | va_MLE_loss=81.9364\n",
      "saved...\n",
      "ITR 1100: || MLE_loss=84.5394 | va_MLE_loss=80.9814\n",
      "saved...\n",
      "ITR 1200: || MLE_loss=81.2076 | va_MLE_loss=80.1474\n",
      "saved...\n",
      "ITR 1300: || MLE_loss=88.4391 | va_MLE_loss=79.5803\n",
      "saved...\n",
      "ITR 1400: || MLE_loss=82.1548 | va_MLE_loss=78.8716\n",
      "saved...\n",
      "ITR 1500: || MLE_loss=81.9064 | va_MLE_loss=77.6815\n",
      "ITR 1600: || MLE_loss=82.3556 | va_MLE_loss=79.2277\n",
      "saved...\n",
      "ITR 1700: || MLE_loss=81.0850 | va_MLE_loss=76.8819\n",
      "saved...\n",
      "ITR 1800: || MLE_loss=77.1248 | va_MLE_loss=74.9444\n",
      "saved...\n",
      "ITR 1900: || MLE_loss=81.0650 | va_MLE_loss=73.2724\n",
      "saved...\n",
      "ITR 2000: || MLE_loss=75.3710 | va_MLE_loss=72.0019\n",
      "saved...\n",
      "ITR 2100: || MLE_loss=73.8369 | va_MLE_loss=71.0445\n",
      "saved...\n",
      "ITR 2200: || MLE_loss=82.7213 | va_MLE_loss=70.4712\n",
      "saved...\n",
      "ITR 2300: || MLE_loss=72.6717 | va_MLE_loss=68.8867\n",
      "saved...\n",
      "ITR 2400: || MLE_loss=69.6994 | va_MLE_loss=66.4320\n",
      "saved...\n",
      "ITR 2500: || MLE_loss=69.2867 | va_MLE_loss=65.3210\n",
      "saved...\n",
      "ITR 2600: || MLE_loss=68.3073 | va_MLE_loss=63.8489\n",
      "saved...\n",
      "ITR 2700: || MLE_loss=66.1179 | va_MLE_loss=61.6049\n",
      "saved...\n",
      "ITR 2800: || MLE_loss=65.4273 | va_MLE_loss=60.0631\n",
      "saved...\n",
      "ITR 2900: || MLE_loss=63.2639 | va_MLE_loss=58.7710\n",
      "saved...\n",
      "ITR 3000: || MLE_loss=62.0972 | va_MLE_loss=56.7971\n",
      "saved...\n",
      "ITR 3100: || MLE_loss=62.1275 | va_MLE_loss=56.4954\n",
      "saved...\n",
      "ITR 3200: || MLE_loss=60.0726 | va_MLE_loss=55.0535\n",
      "saved...\n",
      "ITR 3300: || MLE_loss=62.0625 | va_MLE_loss=54.5773\n",
      "saved...\n",
      "ITR 3400: || MLE_loss=57.0700 | va_MLE_loss=51.6040\n",
      "saved...\n",
      "ITR 3500: || MLE_loss=57.5898 | va_MLE_loss=50.9523\n",
      "ITR 3600: || MLE_loss=57.5296 | va_MLE_loss=51.1391\n",
      "saved...\n",
      "ITR 3700: || MLE_loss=54.9715 | va_MLE_loss=48.7334\n",
      "saved...\n",
      "ITR 3800: || MLE_loss=54.1094 | va_MLE_loss=47.8342\n",
      "saved...\n",
      "ITR 3900: || MLE_loss=54.7033 | va_MLE_loss=47.6800\n",
      "saved...\n",
      "ITR 4000: || MLE_loss=52.1381 | va_MLE_loss=45.9823\n",
      "saved...\n",
      "ITR 4100: || MLE_loss=50.4887 | va_MLE_loss=45.2597\n",
      "saved...\n",
      "ITR 4200: || MLE_loss=49.9445 | va_MLE_loss=44.7531\n",
      "ITR 4300: || MLE_loss=49.6621 | va_MLE_loss=45.4434\n",
      "saved...\n",
      "ITR 4400: || MLE_loss=50.6736 | va_MLE_loss=44.0152\n",
      "saved...\n",
      "ITR 4500: || MLE_loss=48.3132 | va_MLE_loss=43.1007\n",
      "saved...\n",
      "ITR 4600: || MLE_loss=48.2566 | va_MLE_loss=42.5950\n",
      "saved...\n",
      "ITR 4700: || MLE_loss=48.2940 | va_MLE_loss=42.0735\n",
      "saved...\n",
      "ITR 4800: || MLE_loss=46.1448 | va_MLE_loss=41.8575\n",
      "saved...\n",
      "ITR 4900: || MLE_loss=45.9805 | va_MLE_loss=40.1183\n",
      "saved...\n",
      "ITR 5000: || MLE_loss=44.3887 | va_MLE_loss=39.0890\n",
      "saved...\n",
      "ITR 5100: || MLE_loss=43.9195 | va_MLE_loss=38.3747\n",
      "saved...\n",
      "ITR 5200: || MLE_loss=44.1016 | va_MLE_loss=38.1322\n",
      "saved...\n"
     ]
    }
   ],
   "source": [
    "sess, model_init = train.train_init(DATA, input_dims, network_settings, train_parameters_init, init_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess, model_clustered, results = train.train_DeepTPC(DATA, input_dims, network_settings, train_parameters_init, train_parameters_cluster, init_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OUT_ITR:{} || K:{}'.format(out_itr, 4))\n",
    "open_path = init_path + 'K{}/'.format(out_itr, 4)\n",
    "\n",
    "tr_S = results['tr_S']\n",
    "mu_z = results['mu_z']\n",
    "mu_y = results['mu_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, te_S = clustering.kmeans_MTPP_TEST(\n",
    "    model_clustered, \n",
    "    te_M, te_D, te_X, te_Mask, mu_z, mu_y, delta_range, \n",
    "    num_Cluster, 1.0, train_parameters_cluster['beta_cluster'], train_parameters_cluster['beta_ms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 100\n",
    "te_predictions, te_measure = evaluate.evaluate_DeepTPC_cohesion_n_separation(model_clustered, \n",
    "                                                                    te_M, \n",
    "                                                                    te_D, \n",
    "                                                                    te_X, \n",
    "                                                                    te_S, \n",
    "                                                                    te_Mask, \n",
    "                                                                    mu_z, \n",
    "                                                                    mu_y, \n",
    "                                                                    delta_range,\n",
    "                                                                    num_sample)\n",
    "\n",
    "\n",
    "print('|| cohesion score = {:.4f} | silhouette index = {:.4f} ||'.format(\n",
    "    np.mean(te_measure['similarity_sample_vs_sample']),\n",
    "    np.mean(te_measure['s_silhouette_score']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
